{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to google account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 드라이브 연결\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall5(answer_df, submission_df):\n",
    "    \"\"\"\n",
    "    Calculate recall@5 for given dataframes.\n",
    "\n",
    "    Parameters:\n",
    "    - answer_df: DataFrame containing the ground truth\n",
    "    - submission_df: DataFrame containing the predictions\n",
    "\n",
    "    Returns:\n",
    "    - recall: Recall@5 value\n",
    "    \"\"\"\n",
    "\n",
    "    primary_col = answer_df.columns[0]\n",
    "    secondary_col = answer_df.columns[1]\n",
    "\n",
    "    # submission의 예측이 각각 5개인지 확인\n",
    "    prediction_counts = submission_df.groupby(primary_col).size()\n",
    "    if not all(prediction_counts == 5):\n",
    "        raise ValueError(f\"Each {primary_col} should have exactly 5 {secondary_col} predictions.\")\n",
    "\n",
    "\n",
    "    # submission의 예측된 값들에 null값이 있는지 확인\n",
    "    if submission_df[secondary_col].isnull().any():\n",
    "        raise ValueError(f\"Predicted {secondary_col} contains NULL values.\")\n",
    "\n",
    "    # 예측값에 중복이 있는지 확인\n",
    "    duplicated_preds = submission_df.groupby(primary_col).apply(lambda x: x[secondary_col].duplicated().any())\n",
    "    if duplicated_preds.any():\n",
    "        raise ValueError(f\"Predicted {secondary_col} contains duplicates for some {primary_col}.\")\n",
    "\n",
    "\n",
    "    # primary_col 즉 resume_seq가 양측에 있는지 확인 후 남김\n",
    "    submission_df = submission_df[submission_df[primary_col].isin(answer_df[primary_col])]\n",
    "\n",
    "    # For each primary_col, get the top 5 predicted secondary_col values\n",
    "    top_5_preds = submission_df.groupby(primary_col).apply(lambda x: x[secondary_col].head(5).tolist()).to_dict()\n",
    "\n",
    "    # Convert the answer_df to a dictionary for easier lookup\n",
    "    true_dict = answer_df.groupby(primary_col).apply(lambda x: x[secondary_col].tolist()).to_dict()\n",
    "\n",
    "\n",
    "    individual_recalls = []\n",
    "    for key, val in true_dict.items():\n",
    "        if key in top_5_preds:\n",
    "            correct_matches = len(set(true_dict[key]) & set(top_5_preds[key]))\n",
    "            individual_recall = correct_matches / min(len(val), 5) # 공정한 평가를 가능하게 위하여 분모(k)를 'min(len(val), 5)' 로 설정함\n",
    "            individual_recalls.append(individual_recall)\n",
    "\n",
    "\n",
    "    recall = np.mean(individual_recalls)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 Import\n",
    "import random\n",
    "import numpy as np # 행렬 계산에 사용하는 모듈\n",
    "import pandas as pd # 데이터 처리와 분석을 위한 모듈\n",
    "import matplotlib.pyplot as plt # 데이터 시각화를 위한 모듈. 2D, 3D 그릴 때 사용\n",
    "import seaborn as sns # 데이터 시각화를 위한 모듈. 두 데이터의 관계를 볼때 사용\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, SparsePCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리를 간편하게 사용하는 것을 도와준다. 모델 class 처럼 사용 가능\n",
    "# dot을 이용해 객체를 불러 사용. JSON 다룰때 유용.\n",
    "import easydict\n",
    "args = easydict.EasyDict()\n",
    "\n",
    "# path\n",
    "args.default_path = \"/content/data/MyDrive/Playdata/Competitions/ML/Dacon/\" # 메인 경로\n",
    "args.apply_train_path = args.default_path + \"apply_train.csv\" # train 데이터 경로\n",
    "args.company_path = args.default_path + \"company.csv\"\n",
    "args.recruitment_path = args.default_path + \"recruitment.csv\"\n",
    "args.resume_certificate_path = args.default_path + \"resume_certificate.csv\"\n",
    "args.resume_education_path = args.default_path + \"resume_education.csv\"\n",
    "args.resume_language_path = args.default_path + \"resume_language.csv\"\n",
    "args.resume_path = args.default_path + \"resume.csv\"\n",
    "\n",
    "args.default_submission_path = args.default_path + \"sample_submission.csv\" # 예측결과(제출파일) 경로\n",
    "\n",
    "# 데이터 분석을 위한 변수들\n",
    "# # 난수 생성 제어 => 같은 코드를 실행해도 동일한 결과를 얻기 위해서 설정\n",
    "# 데이터 분할 및 모델 초기화 때 유용.\n",
    "args.random_state = 42\n",
    "args.results = [] # 결과 저장 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.submission_path = args.default_path + \"result/submission_Model_2.csv\" # 결과 저장 파일\n",
    "args.save_results = args.default_path+\"result/model_results_Model_2.json\" # 결과 저장 json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_train_df = pd.read_csv(args.apply_train_path) # apply_train -> DataFrame화\n",
    "company_df = pd.read_csv(args.company_path) # company -> DataFrame화\n",
    "recruitment_df = pd.read_csv(args.recruitment_path) # recruitment -> DataFrame화\n",
    "resume_certificate_df = pd.read_csv(args.resume_certificate_path) # resume_certificate -> DataFreame화\n",
    "resume_education_df = pd.read_csv(args.resume_education_path) # resume_education -> DataFrame화\n",
    "resume_language_df = pd.read_csv(args.resume_language_path) # resume_language -> DataFrame화\n",
    "resume_df = pd.read_csv(args.resume_path) # resume -> DataFrame화\n",
    "\n",
    "apply_train = apply_train_df.copy()\n",
    "company = company_df.copy()\n",
    "recruitment = recruitment_df.copy()\n",
    "resume_certificate = resume_certificate_df.copy()\n",
    "resume_education = resume_education_df.copy()\n",
    "resume_language = resume_language_df.copy()\n",
    "resume = resume_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recruitment_seq 기준 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = company.sort_values(by = \"recruitment_seq\")\n",
    "recruitment = recruitment.sort_values(by = \"recruitment_seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_recruitment = pd.merge(recruitment, company, on='recruitment_seq', how='left')\n",
    "merged_recruitment.set_index('recruitment_seq', inplace=True)\n",
    "merged_recruitment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resume_seq 기준 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = resume.sort_values(by='resume_seq')\n",
    "\n",
    "resume_certificate = resume_certificate.sort_values(by='resume_seq')\n",
    "resume_certificate = resume_certificate.dropna(subset=['certificate_contents'])\n",
    "resume_certificate = resume_certificate.groupby('resume_seq')['certificate_contents'].apply(';'.join).reset_index()\n",
    "\n",
    "resume_education = resume_education.sort_values(by='resume_seq')\n",
    "\n",
    "resume_language = resume_language.sort_values(by='resume_seq')\n",
    "resume_language['lang_exam_score'] = resume_language['language'].astype(str) + ';' + resume_language['exam_name'].astype(str) + ';' + resume_language['score'].astype(str)\n",
    "resume_language = resume_language.drop(['language','exam_name', 'score', 'score'], axis=1)\n",
    "resume_language = resume_language.dropna(subset=['lang_exam_score'])\n",
    "resume_language = resume_language.groupby('resume_seq')['lang_exam_score'].apply('&'.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_resume = pd.merge(resume, resume_certificate, on='resume_seq', how='left')\n",
    "merged_resume = pd.merge(merged_resume, resume_education, on='resume_seq', how='left')\n",
    "merged_resume = pd.merge(merged_resume, resume_language, on='resume_seq', how='left')\n",
    "merged_resume.set_index('resume_seq', inplace=True)\n",
    "merged_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merged_recruitment 내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_recruitment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_recruitment.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- address : 범주\n",
    "- career : 다 0?\n",
    "- education : 범주\n",
    "- major_task : 범주\n",
    "- qualifications : 범주\n",
    "- company_type_seq : 범주\n",
    "- supply_kind : 수치\n",
    "- employee : 수치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(merged_recruitment.isnull().sum() / len(merged_recruitment)).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- address_seq1 : mode\n",
    "- address_seq 2 ~ 3 : drop\n",
    "- text_keyword : drop?\n",
    "- company_type_seq, supply_kind, employee : mode?\n",
    "- career_end/start : drop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merged_recruitment 결측치 확인 및 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼제거\n",
    "drop_col = [\"address_seq2\", \"address_seq3\", \"text_keyword\", \"career_end\", \"career_start\"]\n",
    "merged_recruitment.drop(columns = drop_col, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addr_cnt = merged_recruitment[\"address_seq1\"].value_counts()\n",
    "addr_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_type_cnt = merged_recruitment[\"company_type_seq\"].value_counts()\n",
    "com_type_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_kind_cnt = merged_recruitment[\"supply_kind\"].value_counts()\n",
    "supply_kind_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_cnt = merged_recruitment[\"employee\"].value_counts(normalize=True)\n",
    "employee_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addr_mode = merged_recruitment[\"address_seq1\"].mode().values[0]\n",
    "company_type_mode = merged_recruitment[\"company_type_seq\"].mode().values[0]\n",
    "supply_kind_mode = merged_recruitment[\"supply_kind\"].mode().values[0]\n",
    "employee_median = merged_recruitment[\"employee\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_recruitment[\"address_seq1\"].fillna(addr_mode, inplace = True)\n",
    "merged_recruitment[\"company_type_seq\"].fillna(company_type_mode, inplace = True)\n",
    "merged_recruitment[\"supply_kind\"].fillna(supply_kind_mode, inplace = True)\n",
    "merged_recruitment[\"employee\"].fillna(employee_median, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(merged_recruitment.isnull().sum() / len(merged_recruitment)).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merged_resume 내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_resume.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_resume.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_resume.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- degree : 범주\n",
    "- updated_date : 날짜\n",
    "- hope_salary : 수치\n",
    "- last_salary : 수치\n",
    "- career_month : 수치\n",
    "- hischool_type_seq : 범주?\n",
    "- hischool_location_seq : 범주\n",
    "- univ_type_seq1 : 범주\n",
    "- univ_type_seq2 : 범주\n",
    "- univ_transfer : ?\n",
    "- univ_location :범주\n",
    "- univ_major_type : 범주\n",
    "- univ_score : 수치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(merged_resume.isnull().sum() / len(merged_resume)).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- job_code_seq3, univ_sub_major, job_code_seq2, lang_exam_score = drop\n",
    "- text_keyword, career_job_code, certificate_contents, univ_major : 확률 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merged_resume 결측치 확인 및 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = [\"job_code_seq3\", \"univ_sub_major\", \"job_code_seq2\", \"lang_exam_score\" ]\n",
    "merged_resume.drop(columns = drop_col, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(merged_resume.isnull().sum() / len(merged_resume)).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_resume[\"text_keyword\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_resume[\"career_job_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_resume[\"certificate_contents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_resume[\"univ_major\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습, 검증 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습, 검증 분리\n",
    "train, val = [], []\n",
    "apply_train_groupby = apply_train_df.groupby('resume_seq')['recruitment_seq'].apply(list)\n",
    "for uid, iids in zip(apply_train_groupby.index.tolist(), apply_train_groupby.values.tolist()):\n",
    "    for iid in iids[:-1]:\n",
    "        train.append([uid,iid])\n",
    "    val.append([uid, iids[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train, columns=['resume_seq', 'recruitment_seq'])\n",
    "val = pd.DataFrame(val, columns=['resume_seq', 'recruitment_seq'])\n",
    "pred = apply_train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_item_matrix = train.groupby(['resume_seq', 'recruitment_seq']).size().unstack(fill_value=0)\n",
    "pred_user_item_matrix = pred.groupby(['resume_seq', 'recruitment_seq']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_similarity = cosine_similarity(train_user_item_matrix)\n",
    "train_item_similarity = cosine_similarity(train_user_item_matrix.T)\n",
    "\n",
    "pred_user_similarity = cosine_similarity(pred_user_item_matrix)\n",
    "pred_item_similarity = cosine_similarity(pred_user_item_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_predicted_scores = train_user_similarity.dot(train_user_item_matrix)\n",
    "train_item_predicted_scores = train_user_item_matrix.dot(train_item_similarity)\n",
    "\n",
    "pred_user_predicted_scores = pred_user_similarity.dot(pred_user_item_matrix)\n",
    "pred_item_predicted_scores = pred_user_item_matrix.dot(pred_item_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.98\n",
    "train_recommendations = []\n",
    "for idx, user in tqdm(enumerate(train_user_item_matrix.index)):\n",
    "    applied_jobs = set(train_user_item_matrix.loc[user][train_user_item_matrix.loc[user] == 1].index)\n",
    "\n",
    "    # 해당 사용자의 추천 점수 (높은 점수부터 정렬)\n",
    "    sorted_job_indices = (train_item_predicted_scores.loc[user].values * alpha + train_user_predicted_scores[idx]).argsort()[::-1]\n",
    "    recommended_jobs = [job for job in train_user_item_matrix.columns[sorted_job_indices] if job not in applied_jobs][:5]\n",
    "\n",
    "    for job in recommended_jobs:\n",
    "        train_recommendations.append([user, job])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prediction = pd.DataFrame(train_recommendations, columns=['resume_seq', 'recruitment_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall5(val,val_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_recommendations = pd.DataFrame(pred_recommendations, columns=['resume_seq', 'recruitment_seq'])\n",
    "top_recommendations.to_csv(args.submission_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
